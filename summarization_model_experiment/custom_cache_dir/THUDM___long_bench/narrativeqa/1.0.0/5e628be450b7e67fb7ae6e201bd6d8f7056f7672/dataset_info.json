{"description": "LongBench is a comprehensive benchmark for multilingual and multi-task purposes, with the goal to fully measure and evaluate the ability of pre-trained language models to understand long text. This dataset consists of twenty different tasks, covering key long-text application scenarios such as multi-document QA, single-document QA, summarization, few-shot learning, synthetic tasks, and code completion.\n", "citation": "", "homepage": "https://github.com/THUDM/LongBench", "license": "", "features": {"input": {"dtype": "string", "_type": "Value"}, "context": {"dtype": "string", "_type": "Value"}, "answers": [{"dtype": "string", "_type": "Value"}], "length": {"dtype": "int32", "_type": "Value"}, "dataset": {"dtype": "string", "_type": "Value"}, "language": {"dtype": "string", "_type": "Value"}, "all_classes": [{"dtype": "string", "_type": "Value"}], "_id": {"dtype": "string", "_type": "Value"}}, "builder_name": "parquet", "dataset_name": "long_bench", "config_name": "narrativeqa", "version": "1.0.0", "splits": {"test": {"name": "test", "num_bytes": 21682324, "num_examples": 200, "dataset_name": "long_bench"}}, "download_checksums": {"hf://datasets/THUDM/LongBench@a8b3fea296d0126b1887abb5ad2004d9184344fc/narrativeqa/test/0000.parquet": {"num_bytes": 1305985, "checksum": null}}, "download_size": 1305985, "dataset_size": 21682324, "size_in_bytes": 22988309}
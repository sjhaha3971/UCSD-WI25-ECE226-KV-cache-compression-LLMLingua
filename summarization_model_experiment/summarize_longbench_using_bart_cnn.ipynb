{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975d1b61-e6b5-4ea2-be2b-2e059fc91126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import csv\n",
    "from datasets import load_dataset\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922d211f-efa7-4e62-a747-fa336767bdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e07d9f8c7b47ccb06e347001392a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = \"narrativeqa\" # \"multifieldqa_en\"\n",
    "dataset = load_dataset(\"THUDM/LongBench\", dataset_name, split=\"test\", cache_dir=\"custom_cache_dir\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53806ed-dcec-484a-bc4e-fb9ab1336119",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_model_name = 'facebook/bart-large-cnn'\n",
    "summ_model = BartForConditionalGeneration.from_pretrained(summ_model_name).to(device)\n",
    "summ_tokenizer = BartTokenizer.from_pretrained(summ_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c94e64-333a-4865-88d5-3b0d840fbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(input_text, ratio):\n",
    "    inputs = summ_tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "    input_token_length = inputs['input_ids'].shape[1]\n",
    "    target_length = int(input_token_length * ratio)\n",
    "    summary_ids = summ_model.generate(\n",
    "        inputs['input_ids'], \n",
    "        max_length=min(target_length + 100, 1024),  # Maximum summary length based on compression ratio\n",
    "        min_length=target_length,  # Optional: set a minimum length to avoid very short summaries\n",
    "        # length_penalty=2.0,  # Optional: tweak the length penalty to get more compact summaries\n",
    "        num_beams=4,  # Optional: use beam search for better quality\n",
    "        \n",
    "        early_stopping=True  # Stops early if the beam has converged\n",
    "    )\n",
    "    # print(input_token_length, len(summary_ids[0]))\n",
    "    summary = summ_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def generate_multiple_summaries(input_text, ratio):\n",
    "  idx = 0\n",
    "  input_len = len(input_text)\n",
    "  summary = \"\"\n",
    "  while idx < input_len:\n",
    "    end_idx = min(idx+4000, input_len)\n",
    "    summary += \" \" + summarize_text(input_text[idx:end_idx], ratio)\n",
    "    idx = end_idx + 1\n",
    "  return summary\n",
    "\n",
    "def write_dicts_to_csv(data, filename):\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    fieldnames = list(data[0].keys())\n",
    "    # Open the file in append mode if it exists, otherwise write mode\n",
    "    with open(filename, mode='a' if file_exists else 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header only if the file is being created\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        # Write the rows\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff72a93-f9f2-4c01-886b-b079663c47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_summaries(ratio, n, start = 0):\n",
    "    all_data = [None] * n\n",
    "    filename = f\"summarize_{dataset_name}_{int(ratio * 100)}.csv\"\n",
    "    \n",
    "    for i in range(start, start + n):\n",
    "        item = dataset[i].copy()\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # print(i)\n",
    "            summ_context = generate_multiple_summaries(item[\"context\"], ratio)\n",
    "            # print('hi')\n",
    "            item[\"summary\"] = summ_context\n",
    "            all_data[i - start] = item\n",
    "        except Exception as e:\n",
    "            item[\"summary\"] = \"Failed to generate summary\"\n",
    "            print(\"Failed to generate summary :\", e)\n",
    "            all_data[i - start] = item\n",
    "        print(f\"Step {i}: {time.time()-start_time}\")\n",
    "    \n",
    "    write_dicts_to_csv(all_data, filename)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534f9534-92f2-4623-8700-e8dcb5e9c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_25 = generate_dataset_summaries(ratio=0.25, n=50, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e98d44-8b0a-4fb1-ba71-cdb83c4f455b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_data_50 = generate_dataset_summaries(ratio=0.5, n=50, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9bc8d-8c95-4e47-95a9-5f7005dcf6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: 371.13926339149475\n"
     ]
    }
   ],
   "source": [
    "all_data_75 = generate_dataset_summaries(ratio=0.75, n=50, start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89bf3c7-c7c7-4299-b074-ca7bf33dafea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
